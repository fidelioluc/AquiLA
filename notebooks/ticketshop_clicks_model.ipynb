{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64511d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from notebooks.data.feature_scores import calculate_weather_score, calculate_date_score, calculate_team_score, calculate_competition_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e1c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    tickets_df = pd.read_csv(\"notebooks/data/complete/ticket_sales.csv\")\n",
    "    weather_df = pd.read_csv(\"notebooks/data/weather/weather.csv\")\n",
    "    return tickets_df, weather_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d84922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(tickets_df, weather_df):\n",
    "    # Rename columns for consistency\n",
    "    weather_df.rename(columns={'date': 'Date'}, inplace=True)\n",
    "    \n",
    "    # Convert Date columns to datetime\n",
    "    weather_df['Date'] = pd.to_datetime(weather_df['Date'])\n",
    "    tickets_df['Date'] = pd.to_datetime(tickets_df['Date'])\n",
    "    \n",
    "    # Merge the dataframes\n",
    "    merged_df = pd.merge(tickets_df, weather_df, on='Date', how='inner')\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    merged_df.drop(columns=['EventId', 'Venue', 'tsun', 'pres', 'wspd', 'wdir', 'wpgt', 'tmin', 'tmax', 'snow'], inplace=True)\n",
    "\n",
    "    # Remove duplicates\n",
    "    merged_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Extract opponent from EventName\n",
    "    merged_df['Opponent'] = merged_df['EventName'].str.split('vs.').str[1].str.strip()\n",
    "    merged_df.drop(columns=['EventName'], inplace=True)\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Add Seasonal and Competition Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_season_and_competition(merged_df):\n",
    "    def get_season(month):\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'Winter'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'Spring'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'Summer'\n",
    "        else:\n",
    "            return 'Fall'\n",
    "\n",
    "    # Add season column\n",
    "    merged_df['Season'] = merged_df['Date'].dt.month.apply(get_season)\n",
    "\n",
    "    # Clean competition column\n",
    "    merged_df['Competition'] = merged_df['Competition'].str.replace(r'\\s+\\d{4}/\\d{2}', '', regex=True).str.strip()\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cac827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Club Membership and Table Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214ebf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_club_membership():\n",
    "    # Define the membership count for each club\n",
    "    club_membership = {\n",
    "        'FC Bayern München': 400000,\n",
    "        '1. FC Köln': 140000,\n",
    "        'Leipzig': 40000,\n",
    "        'VfL Wolfsburg': 21500,\n",
    "        '1. FC Union Berlin': 70000,\n",
    "        'Bayer 04 Leverkusen': 70000,\n",
    "        'Borussia Dortmund': 218000,\n",
    "        'TSG Hoffenheim': 11000,\n",
    "        'FC Schalke 04': 190000,\n",
    "        'Hertha BSC': 60000,\n",
    "        'SV Werder Bremen': 60000,\n",
    "        'VfB Stuttgart': 120000,\n",
    "        'VfL Bochum 1848': 30000,\n",
    "        'Borussia Mönchengladbach': 102000,\n",
    "        'FC Augsburg': 25000,\n",
    "        '1. FSV Mainz 05': 20000,\n",
    "        'SC Freiburg': 70000,\n",
    "        'SV Darmstadt 98': 14500,\n",
    "        '1. FC Heidenheim': 11000,\n",
    "        'Holstein Kiel': 10000,\n",
    "        'Eintracht Frankfurt': 150000,\n",
    "\n",
    "        # International Clubs - estimates or unclear memberships\n",
    "        'Sporting Clube de Portugal': 160000,\n",
    "        'Tottenham Hotspur': 25000,\n",
    "        'Olympique de Marseille': 25000,\n",
    "        'SSC Napoli': 16000,\n",
    "        'PFC Le': 3000,  \n",
    "        'Aberdeen FC': 10000,\n",
    "        'HJK Helsinki': 5000,\n",
    "        'PAOK FC': 10000,\n",
    "        'Royale Union Saint-Gilloise': 5000,\n",
    "        'FC Viktoria Plzeň': 6000,\n",
    "        'Eintracht Frankfurt': 125000,\n",
    "        'FC RFS': 1000,\n",
    "        'SK Slavia Praha': 12000,\n",
    "        'Ferencvárosi TC': 8000\n",
    "    }\n",
    "    return club_membership\n",
    "\n",
    "def add_opponent_members(merged_df, club_membership):\n",
    "    # Add club membership info for opponents\n",
    "    merged_df['Opponent_Members'] = merged_df['Opponent'].map(club_membership)\n",
    "    return merged_df\n",
    "\n",
    "def add_table_position(merged_df):\n",
    "    top_clubs = ['FC Bayern München', 'Borussia Dortmund', 'Bayer 04 Leverkusen', 'RB Leipzig']\n",
    "    relegation = ['VfL Bochum 1848', 'SV Darmstadt 98', '1. FC Heidenheim', 'Holstein Kiel']\n",
    "    \n",
    "    merged_df['Table_Position_Opponent'] = merged_df['Opponent'].apply(\n",
    "        lambda x: np.random.randint(1, 5) if x in top_clubs else\n",
    "                  np.random.randint(15, 19) if x in relegation else\n",
    "                  np.random.randint(5, 15)\n",
    "    )\n",
    "    merged_df['Table_Position_Home'] = np.random.randint(1,14)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Generate Form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71631cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_form(opponent):\n",
    "    top_clubs = ['FC Bayern München', 'Borussia Dortmund', 'Bayer 04 Leverkusen', 'RB Leipzig']\n",
    "    relegation = ['VfL Bochum 1848', 'SV Darmstadt 98', '1. FC Heidenheim', 'Holstein Kiel']\n",
    "    # Bias depending on opponent strength\n",
    "    if opponent in top_clubs:\n",
    "        probs = [0.6, 0.3, 0.1]  # W, D, L\n",
    "    elif opponent in relegation:\n",
    "        probs = [0.2, 0.3, 0.5]  # Weaker teams lose more\n",
    "    else:\n",
    "        probs = [0.4, 0.3, 0.3]  # Mid-table balanced\n",
    "\n",
    "    outcomes = np.random.choice(['W', 'D', 'L'], size=5, p=probs)\n",
    "    return ''.join(outcomes)\n",
    "\n",
    "def add_form_column(merged_df):\n",
    "    merged_df['Form'] = merged_df['Opponent'].apply(generate_form)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0308d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Filter by Price Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923cb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_price_categories(merged_df):\n",
    "    relevant_categories = ['Kat. 1', 'Kat. 2', 'Kat. 3', 'Kat. 4', 'Kat. 5', 'Kat. 6', 'Stehplatz', 'Stehplatz Gast']\n",
    "    filtered_df = merged_df[merged_df['Price Category'].isin(relevant_categories)].copy()\n",
    "\n",
    "    # Create dictionaries for each category DataFrame\n",
    "    category_dfs = {f'Kat. {i}': filtered_df[filtered_df['Price Category'] == f'Kat. {i}'].copy() for i in range(1, 7)}\n",
    "    category_dfs['Stehplatz'] = filtered_df[filtered_df['Price Category'] == 'Stehplatz'].copy()\n",
    "    category_dfs['Stehplatz Gast'] = filtered_df[filtered_df['Price Category'] == 'Stehplatz Gast'].copy()\n",
    "\n",
    "    return category_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3b790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Scoring Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2ef841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_calculations(merged_df):\n",
    "    merged_df['Weather_Score'] = merged_df.apply(lambda row: calculate_weather_score(\n",
    "        temp=row['tavg'],\n",
    "        precipitation=row['prcp'],\n",
    "        season=row['Season'],\n",
    "    ), axis=1)\n",
    "\n",
    "    merged_df['Date_Score'] = merged_df.apply(lambda row: calculate_date_score(\n",
    "        date_str=str(row['Date']),\n",
    "        time_str=row['Kick-off Time'],\n",
    "    ), axis=1)\n",
    "\n",
    "    merged_df['Team_Score'] = merged_df.apply(lambda row: calculate_team_score(\n",
    "        members=row['Opponent_Members'],\n",
    "        form_string=row['Form'],\n",
    "        home_pos=row['Table_Position_Home'], \n",
    "        opponent_pos=row['Table_Position_Opponent']\n",
    "    ), axis=1)\n",
    "    merged_df['Competition_Score'] = merged_df.apply(lambda row: calculate_competition_score(\n",
    "        competition=row['Competition'],\n",
    "    ), axis=1)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "def add_target_clicks(merged_df):\n",
    "    noise = np.random.normal(0, 100, size=len(merged_df))  # Random noise\n",
    "    merged_df['Website Traffic'] = merged_df['AVG Price']*20000 + noise\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cdd459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Function to Execute Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c701f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Load data\n",
    "    tickets_df, weather_df = load_data()\n",
    "\n",
    "    # Preprocess data\n",
    "    merged_df = preprocess_data(tickets_df, weather_df)\n",
    "\n",
    "    # Add seasonal and competition info\n",
    "    merged_df = add_season_and_competition(merged_df)\n",
    "\n",
    "    # Get club membership and add opponent data\n",
    "    club_membership = map_club_membership()\n",
    "    merged_df = add_opponent_members(merged_df, club_membership)\n",
    "\n",
    "    # Add table position\n",
    "    merged_df = add_table_position(merged_df)\n",
    "\n",
    "    # Add form column\n",
    "    merged_df = add_form_column(merged_df)\n",
    "\n",
    "    # Filter by price category\n",
    "    category_dfs = filter_price_categories(merged_df)\n",
    "\n",
    "\n",
    "    kat1scored_df = score_calculations(category_dfs['Kat. 1'])\n",
    "    kat1scored_df = add_target_clicks(category_dfs['Kat. 1'])\n",
    "\n",
    "    print(kat1scored_df.head())\n",
    "    \n",
    "    kat1scored_df.to_csv('kat1scored.csv', index=False)\n",
    "\n",
    "    X = kat1scored_df.drop(columns=[\"Competition\", \"AVG Price\", \"Website Traffic\", \"Booked Tickets\", \"Price Category\", \"Date\", \"Kick-off Time\", \"tavg\", 'prcp', 'Opponent', 'Season', 'Opponent_Members', 'Table_Position_Opponent', 'Table_Position_Home', 'Form' ])  # Drop Target Variable as well as all other features not available at time of prediction \n",
    "    Y = kat1scored_df[\"Website Traffic\"]  # Target variable\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    mse = mean_squared_error(Y_test, y_pred)\n",
    "    r2 = r2_score(Y_test, y_pred)\n",
    "    mae = mean_absolute_error(Y_test, y_pred)\n",
    "\n",
    "    print(\"Mean Absolut:\", mae)\n",
    "    print(\"Mean Squared Error:\", mse)\n",
    "    print(\"R-squared Score:\", r2)\n",
    "\n",
    "\n",
    "#Print feature importances\n",
    "    feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "   'importance': model.feature_importances_\n",
    "})\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(feature_importance.sort_values('importance', ascending=False))\n",
    "\n",
    "# Optional: Scatter plot of predicted vs actual Revenue \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(Y_test, y_pred)\n",
    "    plt.plot([Y_test.min(), Y_test.max()], [Y_test.min(), Y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Actual Website Trafic')\n",
    "    plt.ylabel('Predicted Website Trafic')\n",
    "    plt.title('Website Trafic')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}